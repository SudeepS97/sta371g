\documentclass{beamer}
\usepackage{../371g-slides}
\usepackage{dcolumn}
\title{Model building: selecting a model 2}
\subtitle{Lecture 10}
\author{STA 371G}

\begin{document}
  <<setup, include=F, cache=F>>=
  opts_knit$set(global.par=T)
  knit_hooks$set(crop=hook_pdfcrop)
  opts_chunk$set(dev='tikz', external=F, fig.path='/tmp/figures/', comment=NA, fig.width=4, fig.height=3, crop=T, sanitize=T, prompt=T, tidy=F)
  knit_theme$set('camo')
  set.seed(1)
  @
  <<include=F, cache=F>>=
  par(fg='#fefefe', col.axis='#fefefe', col.lab='#fefefe', col.main="#fefefe", mar=c(5.1, 4.1, 1.1, 2.1))
  mystery <- read.csv("../../data/mystery.csv")
  counties <- read.csv("../../data/counties.csv", na.strings="")
  counties$PhysiciansPer10000 <-
    counties$Physicians / counties$Population * 10000
  my.counties <- subset(counties, Population > 10000)
  @

  \frame{\maketitle}

  % Show outline at beginning of each section
  \AtBeginSection[]{
    \begin{frame}<beamer>
      \tableofcontents[currentsection]
    \end{frame}
  }

  %%%%%%% Slides start here %%%%%%%

  \begin{darkframes}
    \begin{frame}{Reminders}
      \begin{itemize}
        \item Draft project proposal is due tonight at 11:59 PM.
        \item Midterm 1 is on Wednesday during class; make sure to bring your laptop or borrow one from Media Services, and 1 page of notes. Midterm 1 covers material through Lecture 8.
      \end{itemize}
    \end{frame}

    \begin{frame}
      \fullpagepicture{doc-shortage}
    \end{frame}

    \begin{frame}[fragile]{Potential predictor variables}
      \begin{itemize}
        \item \textbf{LandArea}:       Area in square miles
        \item \textbf{PctRural}:       Percentage rural land
        \item \textbf{MedianIncome}:   Median household income
        \item \textbf{Population}:     Population
        \item \textbf{PctUnder18}:     Percent children
        \item \textbf{PctOver65}:      Percent seniors
        \item \textbf{PctPoverty}:     Percent below the poverty line
        \item \textbf{PctUninsured}:   Percent without health insurance
        \item \textbf{PctSomeCollege}: Percent with some higher education
        \item \textbf{PctUnemployed}:  Percent unemployed
      \end{itemize}
    \end{frame}

    \begin{frame}{Parsimony}
      \begin{itemize}[<+->]
        \item We want a model that has a high $R^2$ and a low $s_e$, because then the predictors are doing a good job of explaining $Y$---and our predictions will be more accurate.
        \item We also want a model that is simple, so it's easy to explain to a non-expert.
        \item The ideal model is \alert{parsimonious}: a good trade-off between simplicity (as few variables as possible) and a high $R^2$.
      \end{itemize}
    \end{frame}

    \begin{frame}{General strategy}
      \begin{enumerate}[<+->]
        \item Use one or more procedures to generate candidate models: possible models that are worth considering.
        \item Select the candidate model with a reasonable tradeoff simplicity and predictive power (high $R^2$).
        \item Check assumptions and model diagnostics (more on this to come); apply transformations and other fixes if needed to the final model. If the problems are unfixable, select a different candidate model.
      \end{enumerate}
    \end{frame}

    \begin{frame}{Backward stepwise regression}
      \begin{enumerate}
        \item Start with a ``full'' model containing all of the predictors.
        \item Remove the least significant (highest $p$-value / smallest $t$-statistic) predictor.
        \item Re-run the model with that predictor removed.
        \item Repeat steps 2-3 until all predictors are significant.
      \end{enumerate}
    \end{frame}

    \begin{frame}{Forward stepwise regression}
      \begin{enumerate}
        \item Start with a ``null'' model containing none of the predictors.
        \item Try adding each predictor, one at a time, and pick the one that ends up being the most significant (lowest $p$-value / highest $t$-statistic) predictor.
        \item Re-run the model with that predictor added.
        \item Repeat steps 2-3 until no more significant predictors can be added.
      \end{enumerate}
    \end{frame}

    \begin{frame}{Other stepwise regression possibilities}
      \begin{itemize}
        \item Add (or remove) variables one at a time based on the change in $R^2$,  Adjusted $R^2$, or AIC (another similar model fit criterion) when that variable is added (or removed).
        \item Run the stepwise regression in both directions, allowing addition or removal of a variable at each step.
        \item R's \texttt{step} function incorporates both of these methods.
      \end{itemize}
    \end{frame}

    \begin{frame}{The problem with stepwise regression}
      Stepwise regression will not necessarily give you the best model; by only adding or removing one variable at a time, you can get locked into a particular ``path'' that means you may never consider better models.
    \end{frame}

    \begin{frame}{Best subsets regression}
      \begin{itemize}
        \item Computers are fast! Just let R try out all of the $2^k-1$ possible models for you.
        \item R will present you the model with the best Adjusted $R^2$ for each possible number of predictors.
      \end{itemize}
    \end{frame}

    \begin{frame}[fragile]{Best-subsets regression}
      \fontsm
       <<fig.keep="none">>=
       library(leaps)
       plot(regsubsets(PhysiciansPer10000 ~ LandArea + PctRural
                        + MedianIncome + Population + PctUnder18
                        + PctOver65 + PctPoverty + PctUninsured
                        + PctSomeCollege + PctUnemployed,
                        data=my.counties), scale="adjr2")
       @
    \end{frame}

    \begin{frame}
      \vspace{-1in}
      <<echo=F, fig.height=4.5>>=
      plot(regsubsets(PhysiciansPer10000 ~ LandArea + PctRural
                       + MedianIncome + Population + PctUnder18
                       + PctOver65 + PctPoverty + PctUninsured
                       + PctSomeCollege + PctUnemployed,
                       data=my.counties), scale="adjr2", col='orange')
      @
    \end{frame}

    \begin{frame}
      \begin{itemize}
        \item Best-subsets regression presents us with a candidate model for each possible number of predictors.
        \item The label on the $y$-axis show the Adjusted $R^2$ value for the model corresponding to the filled-in squares for that row.
      \end{itemize}
    \end{frame}

    \begin{frame}{Putting things together}
      \begin{itemize}[<+->]
        \item Look at multiple statistics. They generally say similar things.
        \item Find the \textbf{parsimonious} middle ground between an underspecified model and extraneous variables.
        \item Fine-tune the model to ensure the model meets assumptions and captures key relationships: you may need to transform predictors and/or add interactions.
        \item Think about logical reasons why certain predictors might be useful; don't just focus on $p$-values.
      \end{itemize}
    \end{frame}

    \begin{frame}[fragile]{Check assumptions of the best model}
      \fontsm
      <<echo=F>>=
      par(mfrow=c(2,2), mar=c(2,2,2,2)) # change the panel layout to 2x2
      @
      <<fig.height=2.5>>=
      candidate <- lm(PhysiciansPer10000 ~ PctRural + PctOver65
                        + PctSomeCollege, data=my.counties)
      plot(candidate)
      @
      <<echo=F>>=
      old.r2 <- summary(candidate)$r.squared
      par(mfrow=c(1,1), mar=c(5.1, 4.1, 4.1, 2.1)) # change the panel layout back
      @
    \end{frame}

    \begin{frame}
      \fullpagepicture{mystery-spot}
    \end{frame}

    \begin{frame}{How reliable is $R^2$?}
      \begin{itemize}[<+->]
        \item The mystery data set contains 20 predictor variables X1-X20.
        \item Backwards stepwise regression or best subsets regression yields a data set with multiple significant predictors.
      \end{itemize}
    \end{frame}

    \begin{frame}[fragile]
      \fontvsm
      <<>>=
      parsimonious.model <- lm(Y ~ X10 + X13 + X16, data=mystery)
      summary(parsimonious.model)
      @
    \end{frame}

    \begin{frame}{Mystery revealed!}
      \begin{itemize}[<+->]
        \item This data set consists of nothing but random numbers!
        \item Remember that when we set $\alpha=0.05$ as we usually do, our Type I error is 5\%, meaning 1 out of roughly every 20 variables will be significant just by chance.
        \item As a result, it's dangerous to build a model by just selecting the most significant from among a large list of variables.
        \item Doing so can result in \alert{overfitting}: creating a model that fits the noise in the data well but won't generalize well to new data.
        \item In general, the $R^2$ of a model gives an overoptimistic view of how well it will generalize to new data.
      \end{itemize}
    \end{frame}

    \begin{frame}{Combatting overfitting with training and test sets}
      \begin{center}
        \tikzstyle{block} = [rectangle, draw, fill=darkgray,
          text centered, minimum height=2em]
        \tikzstyle{line} = [draw, -latex']

        \begin{tikzpicture}[auto]
          \node [block, text width = 10cm] (all) {Original data set};
          \node [block, below of=all, text width = 7cm, xshift=-1.5cm] (training) {Training set};
          \node [block, right of=training, node distance = 5cm, text width = 3cm] (test) {Test set};
        \end{tikzpicture}
      \end{center}

      \begin{itemize}
        \item Split the data into a \alert{training set} and a \alert{test set} (a typical split is 70\% training set / 30\% test set).
        \item We use the training set to build the model, and then evaluate the quality of the model on how well it predicts $Y$ in the test set.
      \end{itemize}
    \end{frame}

    \begin{frame}[fragile]
      \fontsm
      First, we'll take 50 random cases for the test set (about 30\% of the $n=168$ cases in the whole data set), and the rest for the training set:
      <<>>=
      test.cases <- sample(1:168, 50)
      training.cases <- setdiff(1:168, test.cases)
      training.set <- my.counties[training.cases,]
      test.set <- my.counties[test.cases,]
      @

      \pause

      Then, we ``train'' the model using the cases in the \alert{training} set, instead of the whole data set:
      <<>>=
      candidate <- lm(PhysiciansPer10000 ~ PctRural + PctOver65
                        + PctSomeCollege, data=training.set)
      @
    \end{frame}

    \begin{frame}[fragile]
      Finally, we predict $Y$ for each value in the \alert{test} set using this model:
      <<>>=
      predicted.y <- predict(candidate, test.set)
      @

      \pause

      We can calculate $R^2$ in the test set using the fact that $R^2 = \text{cor}(\hat Y, Y)^2$:
      <<>>=
      y <- test.set$PhysiciansPer10000
      cor(predicted.y, y)^2
      @

      \pause

      This is somewhat lower than the $R^2$ from the original model (\Sexpr{round(old.r2, 2)}), but it's a fairer estimate of how good our model will perform on unseen data.
    \end{frame}

    \begin{frame}{Be careful of getting too crazy!}
      \begin{itemize}[<+->]
        \item A general guideline is that you should not even consider more than one variable for every 10 to 15 cases in your dataset.
        \item Think about the meaning of the variables in your model. Be careful if the model looks too good to be true.
        \item Do not just use a mechanical process for model selection and call it a day; you need to use your judgement and select a parsimonious model.
        \item Consider using a training/test set split to ensure you are not ``capitalizing on chance.''
        \item Don't forget to check the model assumptions for your final model!
      \end{itemize}
    \end{frame}

  \end{darkframes}

\end{document}

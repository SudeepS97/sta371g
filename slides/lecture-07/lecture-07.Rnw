\documentclass{beamer}
\usepackage{../371g-slides}
\title{Multiple regression 1}
\subtitle{Lecture 7}
\author{STA 371G}

\begin{document}
  <<setup, include=F, cache=F>>=
  opts_knit$set(global.par=T)
  knit_hooks$set(crop=hook_pdfcrop)
  opts_chunk$set(dev='tikz', external=F, fig.path='/tmp/figures/', comment=NA, fig.width=4, fig.height=3, crop=T, sanitize=T, prompt=T, tidy=F)
  knit_theme$set('camo')
  @
  <<include=F, cache=F>>=
  par(fg='#fefefe', col.axis='#fefefe', col.lab='#fefefe', col.main="#fefefe", mar=c(5.1, 4.1, 1.1, 2.1))
  colleges <- read.csv("../../data/colleges.csv")
  @

  \frame{\maketitle}

  % Show outline at beginning of each section
  \AtBeginSection[]{
    \begin{frame}<beamer>
      \tableofcontents[currentsection]
    \end{frame}
  }

  %%%%%%% Slides start here %%%%%%%

  \begin{darkframes}
    \begin{frame}{Why do some colleges have higher graduation rates than others?}
      \begin{itemize}[<+->]
        \item What factors do you think impact the graduation rate of a college?
        \item It seems like there is no \emph{one} factor that dominates---it is probably true that to make a good prediction we need to put a lot of variables together, so simple regression is likely not sufficient.
        \item \alert{Multiple regression} allows us to build on simple regression by predicting one $Y$ variable using multiple $X$ variables.
      \end{itemize}
    \end{frame}

    \begin{frame}{The colleges data set}
      Today's data set is a sample of \Sexpr{nrow(colleges)} colleges with various factors about the colleges, including SAT scores, student/faculty ratios, tuition rates, acceptance rates, etc.
    \end{frame}

    \begin{frame}[fragile]
      <<echo=F>>=
      my.sample <- subset(colleges, !is.na(Average.combined.SAT) & Graduation.rate <= 100)
      model.sat <- lm(Graduation.rate ~ Average.combined.SAT, data=my.sample)
      model.tuition <- lm(Graduation.rate ~ In.state.tuition, data=my.sample)
      options(digits=3)
      @
      \begin{center}
        SAT scores and (in-state) tuition were the two best single predictors, with $R^2$ values of \Sexpr{summary(model.sat)$r.squared} and \Sexpr{summary(model.tuition)$r.squared}, respectively. Can we combine these together and get an $R^2$ that is better than either predictor would produce on its own?
      \end{center}
    \end{frame}

    \begin{frame}{Using multiple predictors to predict graduation rate}
      The simple regression models were:
      \[
        Y_i = \beta_0 + \beta_1 (\text{SAT}) + \epsilon_i
      \]
      and
      \[
        Y_i = \beta_0 + \beta_1 (\text{tuition}) + \epsilon_i.
      \]
      The multiple regression model is
      \[
        Y_i = \beta_0 + \beta_1 (\text{tuition}) + \beta_2 (\text{SAT}) + \epsilon_i.
      \]
    \end{frame}

    \begin{frame}[fragile]
      \fontsize{8}{8}
      <<>>=
      model <- lm(Graduation.rate ~ Average.combined.SAT + In.state.tuition, data=my.sample)
      summary(model)
      @
    \end{frame}

    \begin{frame}
      The multiple regression prediction equation is:
      <<echo=F>>=
      options(scipen=5, digits=4)
      @
      \[
        \widehat{\text{Graduation rate}} =
          \Sexpr{coefficients(model)["(Intercept)"]} +
          \Sexpr{coefficients(model)["Average.combined.SAT"]}(\text{SAT})
          + \Sexpr{coefficients(model)["In.state.tuition"]}(\text{tuition})
      \]
      \pause
      We can use this to make predictions like we would for a simple regression!
    \end{frame}

    \begin{frame}[fragile]
      <<echo=F, fig.width=4.5, fig.height=4>>=
      library(scatterplot3d)
      result <- scatterplot3d(my.sample$Average.combined.SAT, my.sample$In.state.tuition, my.sample$Graduation.rate, highlight.3d=TRUE, xlab="SAT", ylab="Tuition", zlab="Graduation rate", zlim=c(0, 100), pch=16)
      @
    \end{frame}

    \begin{frame}[fragile]
      <<echo=F, fig.width=4.5, fig.height=4>>=
      library(scatterplot3d)
      result <- scatterplot3d(my.sample$Average.combined.SAT, my.sample$In.state.tuition, my.sample$Graduation.rate, highlight.3d=TRUE, xlab="SAT", ylab="Tuition", zlab="Graduation rate", zlim=c(0, 100), pch=16)
      result$plane3d(model)
      @
    \end{frame}

    \begin{frame}{Interpreting the coefficients: intercept}
      Let's interpret the intercept coefficient of $\Sexpr{coefficients(model)["(Intercept)"]}$:
      \begin{itemize}[<+->]
        \item The predicted graduation rate when the average SAT score is 0 and the in-state tuition is \$0 is $\Sexpr{coefficients(model)["(Intercept)"]}$.
        \item This is not a meaningful number on its own in this case, since there will never be a school with those particular predictor values! (The intercept might be interpretable for other models.)
      \end{itemize}
    \end{frame}

    \begin{frame}{Interpreting the coefficients: SAT}
      Let's interpret the SAT coefficient of \Sexpr{coefficients(model)["Average.combined.SAT"]}:
      \begin{itemize}[<+->]
        \item \alert{Holding tuition constant}, each additional SAT score point  increases our predicted graduation rate by \Sexpr{coefficients(model)["Average.combined.SAT"]} percentage points.
        \item \alert{Among colleges that have the same tuition}, an increase in SAT of 1 point would result in a predicted graduation rate that is \Sexpr{coefficients(model)["Average.combined.SAT"]} percentage points higher.
        \item \alert{If we compared two colleges that have the same tuition but differ in average SAT scores by 1 point}, the college with the higher SAT score would be predicted to have a graduation rate that is \Sexpr{coefficients(model)["Average.combined.SAT"]} percentage points higher.
      \end{itemize}
    \end{frame}

    \begin{frame}{Interpreting the coefficients: tuition}
      Let's interpret the tuition coefficient of \Sexpr{coefficients(model)["In.state.tuition"]}:
      \begin{itemize}[<+->]
        \item \alert{Holding SAT constant}, each additional dollar of in-state tuition increases our predicted graduation rate by \Sexpr{coefficients(model)["In.state.tuition"]} percentage points.
        \item \alert{Among colleges that have the same average SAT scores}, an increase in tuition of \$1 would result in a predicted graduation rate that is \Sexpr{coefficients(model)["In.state.tuition"]} percentage points higher.
        \item \alert{If we compared two colleges that have the same average SAT scores but differ in their tuition by \$1}, the college with the higher tuition would be predicted to have a graduation rate that is \Sexpr{coefficients(model)["In.state.tuition"]} percentage points higher.
      \end{itemize}
    \end{frame}

    \begin{frame}{What's the difference?!}
      \begin{itemize}[<+->]
        \item The difference between ``the predicted effect of a 1-point increase in SAT score'' and ``the predicted effect of a 1-point increase in SAT score, holding tuition constant'' really are \alert{two different things}.
        \item The relationship between $X_1$ and $Y$ may change when we \alert{control for} (i.e., add to the model) another predictor $X_2$.
      \end{itemize}
    \end{frame}

    \begin{frame}{$R^2$}
      \begin{itemize}[<+->]
        \item $R^2$ has a similar meaning as in simple regression: how much of the variation in the response variable ($Y$) are explained by the predictor variables ($X$'s) together?
        \item Another way to think about $R^2$ is that \[ R^2 = \frac{\text{Var}(\hat Y)}{\text{Var}(Y)}, \] i.e., it represents how much variance in $Y$ the model predicts.
        \item $R^2$ always increases when you add more variables, \alert{even if you add variables that have no real relationship with $Y$}.
      \end{itemize}
    \end{frame}

    \begin{frame}[fragile]
      <<include=F>>=
      set.seed(4)
      options(digits=9)
      @
      \fontsize{8}{8}
      <<>>=
      model1 <- lm(Graduation.rate ~ Average.combined.SAT + In.state.tuition,
                   data=my.sample)
      summary(model1)
      @
    \end{frame}

    \begin{frame}[fragile]
      \fontsize{8}{8}
      <<>>=
      Random.numbers <- rnorm(nrow(my.sample))
      model2 <- lm(Graduation.rate ~ Average.combined.SAT + In.state.tuition
                     + Random.numbers, data=my.sample)
      summary(model2)
      @
    \end{frame}

    \begin{frame}{Adjusted $R^2$}
      \begin{itemize}[<+->]
        \item There are many, many possible models (think of how many combinations of predictors there are!) so we need some criterion to determine which model is best.
        \item $R^2$ is not good because adding even a variable of random numbers increases $R^2$.
        \item \alert{Adjusted $R^2$} makes an adjustment to $R^2$ by adding a penalty for each variable added (in this example, adjusted $R^2$ went down even though $R^2$ increased).
      \end{itemize}
    \end{frame}

    \begin{frame}[fragile]
      <<include=F>>=
      set.seed(4)
      options(digits=9)
      @
      \fontsize{8}{8}
      <<>>=
      model1 <- lm(Graduation.rate ~ Average.combined.SAT + In.state.tuition,
                   data=my.sample)
      summary(model1)
      @
    \end{frame}

    \begin{frame}[fragile]
      \fontsize{8}{8}
      <<>>=
      Random.numbers <- rnorm(nrow(my.sample))
      model2 <- lm(Graduation.rate ~ Average.combined.SAT + In.state.tuition
                     + Random.numbers, data=my.sample)
      summary(model2)
      @
    \end{frame}

    \begin{frame}{Which model is the best?}
      \begin{itemize}[<+->]
        \item In general, we want to select the model that is the most \alert{parsimonious}, that is, the model that has the best combination of being simple with a high $R^2$.
        \item This is easier said than done---using Adjusted $R^2$ is not enough. We'll come back to this next week!
      \end{itemize}
    \end{frame}
  \end{darkframes}

\end{document}

\documentclass{beamer}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{1, 0.894, 0.769}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.824,0.412,0.118}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{1,0.894,0.71}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.824,0.706,0.549}{#1}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{1,0.894,0.769}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{1,0.894,0.769}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.941,0.902,0.549}{#1}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.804,0.776,0.451}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.78,0.941,0.545}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{1,0.78,0.769}{#1}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage{preview}
\usepackage{../371g-slides}
\title{Logistic regression 2}
\subtitle{Lecture 18}
\author{STA 371G}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}
  
  

  \frame{\maketitle}

  % Show outline at beginning of each section
  \AtBeginSection[]{
    \begin{frame}<beamer>
      \tableofcontents[currentsection]
    \end{frame}
  }

  %%%%%%% Slides start here %%%%%%%

  \begin{darkframes}
    \begin{frame}{Reminder}
      \begin{itemize}
        \item Remember that Part 3 of the project is due on Friday at 11:59 PM!
      \end{itemize}
    \end{frame}

    \begin{frame}<beamer>
      \tableofcontents
    \end{frame}

    \section{Logistic regression with 2+ predictors}

    \begin{frame}{Adding another predictor}
      \begin{itemize}
        \item Just like with a linear regression model, we can add additional predictors to the model.
        \item Our interpretation of the coefficients in multiple logistic regression is similar to multiple linear regression, in the sense that each coefficient represents the predicted effect of one $X$ on $Y$, holding the other $X$ variables constant.
      \end{itemize}
    \end{frame}

    \begin{frame}[fragile]{Adding another predictor}
      Let's add sexual orientation as a second predictor of gender, in addition to height:
      
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlstd{model2} \hlkwb{<-} \hlkwd{glm}\hlstd{(male} \hlopt{~} \hlstd{height} \hlopt{+} \hlstd{orientation,}
  \hlkwc{data}\hlstd{=my.profiles,} \hlkwc{family}\hlstd{=binomial)}
\end{alltt}
\end{kframe}
\end{knitrout}
      The \texttt{orientation} variable has three categories:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlkwd{table}\hlstd{(my.profiles}\hlopt{$}\hlstd{orientation)}
\end{alltt}
\begin{verbatim}

bisexual      gay straight 
    2763     5568    51495 
\end{verbatim}
\end{kframe}
\end{knitrout}
    \end{frame}

    \begin{frame}[fragile]
      \fontvsm\vspace{-0.3cm}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{verbatim}

Call:
glm(formula = male ~ height + orientation, family = binomial, 
    data = my.profiles)

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-3.620  -0.481   0.198   0.530   4.022  

Coefficients:
                     Estimate Std. Error z value Pr(>|z|)    
(Intercept)         -46.08076    0.37167  -124.0   <2e-16 ***
height                0.66535    0.00537   124.0   <2e-16 ***
orientationgay        2.09556    0.07209    29.1   <2e-16 ***
orientationstraight   1.39972    0.06068    23.1   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 80654  on 59825  degrees of freedom
Residual deviance: 43722  on 59822  degrees of freedom
AIC: 43730

Number of Fisher Scoring iterations: 6
\end{verbatim}
\end{kframe}
\end{knitrout}
    \end{frame}

    \begin{frame}{Interpreting coefficients}
      Our prediction equation is:
      
      \[
        \log\left(\frac{p}{1-p}\right) =
          -46.08 +
          0.67\cdot\text{height} +
          2.1\cdot\text{gay} +
          1.4\cdot\text{straight}.
      \]
      This means that:
      \begin{itemize}[<+->]
        \item Our predicted log odds of being male for someone who is bisexual and has a height of 0" is $-46.08$ (the intercept).
        \item Among people with the same sexual orientation, each additional inch of height corresponds to an increase in 95\% in predicted odds of being male (i.e., multiplied by $e^{0.67} = 1.95$).
      \end{itemize}
    \end{frame}

    \begin{frame}{Interpreting coefficients}
      \[
        \log\left(\frac{p}{1-p}\right) =
          -46.08 +
          0.67\cdot\text{height} +
          2.1\cdot\text{gay} +
          1.4\cdot\text{straight}.
      \]
      \begin{itemize}[<+->]
        \item Among people of the same height, being gay increases the predicted odds of being male by 713\% (i.e., multiplied by $e^{2.1} = 8.13$) compared to being bisexual.
        \item Among people of the same height, being straight increases the predicted odds of being male by 305\% (i.e., multiplied by $e^{1.4} = 4.05$) compared to being bisexual.
      \end{itemize}
    \end{frame}

    \begin{frame}[fragile]{Understanding what's going on}
      \fontsm
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlstd{crosstabs} \hlkwb{<-} \hlkwd{table}\hlstd{(my.profiles}\hlopt{$}\hlstd{sex, my.profiles}\hlopt{$}\hlstd{orientation)}
\hlstd{crosstabs}
\end{alltt}
\begin{verbatim}
   
    bisexual   gay straight
  f     1994  1586    20509
  m      769  3982    30986
\end{verbatim}
\end{kframe}
\end{knitrout}
    \end{frame}

    \begin{frame}[fragile]
      \fontsm
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlkwd{barplot}\hlstd{(}\hlkwd{prop.table}\hlstd{(crosstabs,} \hlnum{2}\hlstd{),} \hlkwc{col}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"pink"}\hlstd{,} \hlstr{"lightblue"}\hlstd{),}
  \hlkwc{legend}\hlstd{=T)}
\end{alltt}
\end{kframe}
\input{/tmp/figures/unnamed-chunk-8-1.tex}

\end{knitrout}
    \end{frame}

    \begin{frame}{Converting back to probabilities}
      Because there is a nonlinear relationship between probability and odds, a particular percentage increase in odds does not correspond to a fixed change in probability. But it can be useful sometimes to compute some exemplar predicted probabilities to get a sense of the relationships:

      

      \begin{center}
        \begin{tabular}{r|llll}
          & \multicolumn{4}{c}{Height} \\
          & 60" & 64" & 68" & 72" \\
          \hline
          bisexual
            & 0.002
            & 0.029
            & 0.302
            & 0.861
            \\
          gay
            & 0.017
            & 0.197
            & 0.779
            & 0.981
            \\
          straight
            & 0.008
            & 0.109
            & 0.637
            & 0.962
            \\
        \end{tabular}
      \end{center}
    \end{frame}

    \begin{frame}
      We can also visualize this by plotting the three curves for straight (yellow), gay (green), and bisexual (blue) OkCupid users:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}
\input{/tmp/figures/unnamed-chunk-10-1.tex}

\end{knitrout}
      Where will the curve for bisexual OkCupid users be?
    \end{frame}

    \begin{frame}
      We can also visualize this by plotting the three curves for straight (yellow), gay (green), and bisexual (blue) OkCupid users:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}
\input{/tmp/figures/unnamed-chunk-11-1.tex}

\end{knitrout}
    \end{frame}

    \section{Interactions in logistic regression}

    \begin{frame}{What would interactions do?}
      \begin{itemize}
        \item In linear regression, an interaction between two predictors $X_1$ and $X_2$ means that the \alert{slope} of $X_1$ will depend on the \alert{value} of $X_2$.
        \item In other words, there will be differently-sloped regression lines predicting $Y$ from $X_1$ depending on what the value of $X_2$ is.
      \end{itemize}
    \end{frame}

    \begin{frame}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}
\input{/tmp/figures/unnamed-chunk-12-1.tex}

\end{knitrout}
    \end{frame}

    \begin{frame}{What would interactions do?}
      \begin{itemize}
        \item We can add interactions to logistic regression and the interpretation is the same: the effect of $X_1$ on the \alert{probability of being male} depends on the \alert{value} of $X_2$.
        \item Let's try this out with $X_1=\text{height}$ and $X_2=\text{orientation}$.
      \end{itemize}
    \end{frame}

    \begin{frame}[fragile]
      \fontvsm
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlstd{int.model} \hlkwb{<-} \hlkwd{glm}\hlstd{(male} \hlopt{~} \hlstd{height} \hlopt{*} \hlstd{orientation,} \hlkwc{data}\hlstd{=my.profiles,} \hlkwc{family}\hlstd{=binomial)}
\hlkwd{summary}\hlstd{(int.model)}
\end{alltt}
\begin{verbatim}

Call:
glm(formula = male ~ height * orientation, family = binomial, 
    data = my.profiles)

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-3.655  -0.470   0.194   0.521   4.064  

Coefficients:
                           Estimate Std. Error z value Pr(>|z|)    
(Intercept)                -35.3027     1.4050  -25.13  < 2e-16 ***
height                       0.5076     0.0206   24.67  < 2e-16 ***
orientationgay              -6.2727     1.8365   -3.42  0.00064 ***
orientationstraight        -10.2887     1.4596   -7.05  1.8e-12 ***
height:orientationgay        0.1218     0.0271    4.49  7.1e-06 ***
height:orientationstraight   0.1712     0.0214    8.01  1.2e-15 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 80654  on 59825  degrees of freedom
Residual deviance: 43663  on 59820  degrees of freedom
AIC: 43675

Number of Fisher Scoring iterations: 6
\end{verbatim}
\end{kframe}
\end{knitrout}
    \end{frame}

    \begin{frame}
      The interaction model is:

      \begin{align*}
        \log\left(\frac{p}{1-p}\right) &=
          -35.3 +
          0.51\cdot\text{height}
          - 6.27\cdot\text{gay}
          - 10.29\cdot\text{straight} \\ & \qquad+
          0.12\cdot\text{height}\cdot\text{gay} +
          0.17\cdot\text{height}\cdot\text{straight}.
      \end{align*}
    \end{frame}

    \begin{frame}
      Let's graph the equation for gay (green), yellow (straight), and blue (bisexual) users:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}
\input{/tmp/figures/unnamed-chunk-15-1.tex}

\end{knitrout}
    \end{frame}

    \section{Hypothesis testing when there are 2+ predictors}

    \begin{frame}{Four kinds of hypotheses to test}
      \begin{enumerate}[<+->]
        \item \alert{Overall} null hypothesis: $\beta_1=\beta_2=\cdots=0$ (all of the slope coefficients are 0, the model has no predictive power at all)
        \item \alert{Quantitative variable} null hypothesis: $\beta_i=0$ (there is no relationship between gender and a particular predictor variable, holding constant the other predictors)
        \item \alert{Categorical variable} null hypothesis: $\beta=0$ for all dummy variables corresponding to this categorical variable (there is no relationship between gender and a particular predictor variable, holding constant the other predictors)
        \item \alert{Individual dummy variable coefficient} null hypothesis: $\beta_i=0$ (there is no difference in predicted probability of being male between this level and the reference level, holding constant other predictors)
      \end{enumerate}
    \end{frame}

    \begin{frame}{Likelihood ratio test}
      The \alert{likelihood ratio test} lets us test a null hypothesis of the form: Model A has no more predictive power than Model B.

      \bigskip

      We can use this to test null hypothesis that don't correspond to $p$-values that we can read off the regression output. (And remember that there's no $R^2$ or Adjusted $R^2$ in logistic regression to compare models!)
    \end{frame}

    \begin{frame}[fragile]{Example 1: Overall null hypothesis}
      We'll test the overall null hypothesis by comparing the model to a ``null model'' with no variables:
      \fontvsm
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hlstd{(lmtest)}
\hlkwd{lrtest}\hlstd{(model2)}
\end{alltt}
\begin{verbatim}
Likelihood ratio test

Model 1: male ~ height + orientation
Model 2: male ~ 1
  #Df LogLik Df Chisq Pr(>Chisq)    
1   4 -21861                        
2   1 -40327 -3 36932     <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}
\end{kframe}
\end{knitrout}
    \end{frame}

    \begin{frame}[fragile]{Example 2: Quantitative variable}
      We can test the significance of a quantitative variable (e.g., height) by reading the $p$-value for \texttt{height} off of the regression output:

      \fontvsm
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlkwd{summary}\hlstd{(model2)}
\end{alltt}
\begin{verbatim}
...
                     Estimate Std. Error z value Pr(>|z|)    
(Intercept)         -46.08076    0.37167  -124.0   <2e-16 ***
height                0.66535    0.00537   124.0   <2e-16 ***
orientationgay        2.09556    0.07209    29.1   <2e-16 ***
orientationstraight   1.39972    0.06068    23.1   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

...

\end{verbatim}
\end{kframe}
\end{knitrout}
    \end{frame}

    \begin{frame}[fragile]{Example 3: Categorical variable}
      We'll test the significance of a categorical variable by comparing the model with \texttt{orientation} to the model without it:
      \fontvsm
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlstd{model1} \hlkwb{<-} \hlkwd{glm}\hlstd{(male} \hlopt{~} \hlstd{height,} \hlkwc{data}\hlstd{=my.profiles,} \hlkwc{family}\hlstd{=binomial)}
\hlstd{model2} \hlkwb{<-} \hlkwd{glm}\hlstd{(male} \hlopt{~} \hlstd{height} \hlopt{+} \hlstd{orientation,} \hlkwc{data}\hlstd{=my.profiles,} \hlkwc{family}\hlstd{=binomial)}
\hlkwd{lrtest}\hlstd{(model1, model2)}
\end{alltt}
\begin{verbatim}
Likelihood ratio test

Model 1: male ~ height
Model 2: male ~ height + orientation
  #Df LogLik Df Chisq Pr(>Chisq)    
1   2 -22319                        
2   4 -21861  2   915     <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}
\end{kframe}
\end{knitrout}
    \end{frame}

    \begin{frame}[fragile]{Example 4: Individual dummy variable}
      We can test the significance of the difference between two levels of a categorical variable (e.g. the difference between bisexual and straight) reading the $p$-value for \texttt{height:orientationstraight} off of the regression output:

      \fontvsm
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.137, 0.137, 0.137}\begin{kframe}
\begin{alltt}
\hlkwd{summary}\hlstd{(model2)}
\end{alltt}
\begin{verbatim}
...
                     Estimate Std. Error z value Pr(>|z|)    
(Intercept)         -46.08076    0.37167  -124.0   <2e-16 ***
height                0.66535    0.00537   124.0   <2e-16 ***
orientationgay        2.09556    0.07209    29.1   <2e-16 ***
orientationstraight   1.39972    0.06068    23.1   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

...

\end{verbatim}
\end{kframe}
\end{knitrout}
    \end{frame}

    \section{Other applications of logistic regression}

    \begin{frame}{What else can we use logistic regression for?}
      \begin{itemize}
        \item \textbf{Finance:} Predicting which customers are most likely to default on a loan
        \item \textbf{Advertising:} Predicting when a customer will respond positively to an advertising campaign
        \item \textbf{Marketing:} Predicting when a customer will purchase a product or sign up for a service
      \end{itemize}
    \end{frame}
  \end{darkframes}
\end{document}
